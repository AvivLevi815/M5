{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tests folder\n",
    "import os\n",
    "if not os.path.isdir(\"tests\") :\n",
    "    os.mkdir(\"tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function looks at the data in every column and sets the most efficient data type to it - memory wise. \n",
    "\"\"\"\n",
    "def reduce_mem_usage(props):    \n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",props[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading Kaggle data.\n",
    "\"\"\"\n",
    "calendar = pd.read_csv('C:\\\\Users\\\\Aviv\\\\Desktop\\\\work\\\\kaggle\\\\2020\\\\M5\\\\accuracy\\\\calendar.csv')\n",
    "sales_train_validation = pd.read_csv(\"C:\\\\Users\\\\Aviv\\\\Desktop\\\\work\\\\kaggle\\\\2020\\\\M5\\\\accuracy\\\\sales_train_validation.csv\")\n",
    "sample_submission = pd.read_csv(\"C:\\\\Users\\\\Aviv\\\\Desktop\\\\work\\\\kaggle\\\\2020\\\\M5\\\\accuracy\\\\sample_submission.csv\")\n",
    "sell_prices = pd.read_csv(\"C:\\\\Users\\\\Aviv\\\\Desktop\\\\work\\\\kaggle\\\\2020\\\\M5\\\\accuracy\\\\sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features from calendar data set to train DataFrame\n",
    "MONTH_START = 8\n",
    "train = calendar.drop([\"date\", \"weekday\"], axis = 1).copy()\n",
    "train[\"mday\"] = calendar.date.str[MONTH_START:].astype(\"int\")\n",
    "train[\"special_day\"] = np.where((train[\"event_name_1\"].astype(\"str\") != \"nan\") |\n",
    "                                (train[\"event_name_2\"].astype(\"str\") != \"nan\") , True, False)\n",
    "train = train.drop([\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From classic time series table (every column is a day, every row a product) \n",
    "To a train ready Dataframe - \n",
    "every row is a product at a given day \n",
    "total number of rows = days * products\n",
    "\"\"\"\n",
    "DAYS_COUNT = 1913\n",
    "\n",
    "# month, day,state, department, price, sold\n",
    "sales_train_validation[\"day\"] = 0\n",
    "sales_train_validation[\"sold\"] = 0\n",
    "\n",
    "# take every row - duplicate id 1913 times (once for every day, add the day number to id)\n",
    "# take all d_1.. d_1913 matrix and flatten it - rotate it so it is a column\n",
    "# now you have new id and sold items - so you know item, cat, dept, state and price in every day.\n",
    "\n",
    "# sales_id = sales_train_validation[\"id\"].copy()\n",
    "new_id = sales_train_validation[\"id\"].loc[np.repeat(sales_train_validation.index.values, DAYS_COUNT)].copy()\n",
    "keep_id = new_id.copy()\n",
    "\n",
    "days_array = list(range(1,DAYS_COUNT + 1))\n",
    "number_of_items = sales_train_validation.shape[0]\n",
    "all_days = pd.Series(days_array * number_of_items)\n",
    "\n",
    "new_id.index = all_days.index\n",
    "keep_id.index = new_id.index\n",
    "new_id = new_id.astype(\"str\") + all_days.astype(\"str\")\n",
    "\n",
    "days = [col for col in sales_train_validation if \"d_\" in col]\n",
    "only_days_sales = np.array(sales_train_validation[days].copy()).flatten()\n",
    "\n",
    "product_sales = pd.DataFrame({\"id\": new_id, \"sales\": only_days_sales})\n",
    "\n",
    "product_sales[\"product_id\"] = keep_id\n",
    "product_sales[\"d\"] =\"d_\" + all_days.astype(\"str\")\n",
    "\n",
    "product_sales = product_sales.merge(train, how=\"left\", on=\"d\")\n",
    "\n",
    "product_sales = product_sales.merge(sales_train_validation[[\"id\", \"dept_id\", \"state_id\",\"item_id\",\"store_id\"]], how=\"left\", left_on=\"product_id\", right_on=\"id\")\n",
    "\n",
    "product_sales = product_sales.rename(columns = {\"id_x\": \"id\"})\n",
    "product_sales = product_sales.drop(\"id_y\", axis = 1)\n",
    "\n",
    "product_sales = product_sales.merge(sell_prices, how=\"left\", on = [\"store_id\", \"item_id\", \"wm_yr_wk\"])\n",
    "# product_sales = product_sales.dropna()\n",
    "# product_sales[\"sell_price\"] = product_sales[\"sell_price\"].astype(\"int\")\n",
    "\n",
    "product_sales = product_sales.drop(\"sell_price\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "      <th>product_id</th>\n",
       "      <th>d</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>mday</th>\n",
       "      <th>special_day</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation1</td>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>d_1</td>\n",
       "      <td>11101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>CA_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  sales                     product_id    d  \\\n",
       "0  HOBBIES_1_001_CA_1_validation1      0  HOBBIES_1_001_CA_1_validation  d_1   \n",
       "\n",
       "   wm_yr_wk  wday  month  year  snap_CA  snap_TX  snap_WI  mday  special_day  \\\n",
       "0     11101     1      1  2011        0        0        0    29        False   \n",
       "\n",
       "     dept_id state_id        item_id store_id  \n",
       "0  HOBBIES_1       CA  HOBBIES_1_001     CA_1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_sales.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Label Encode department and state.\n",
    "\"\"\"\n",
    "le_dept = LabelEncoder()\n",
    "le_state = LabelEncoder()\n",
    "\n",
    "categorical_cols = [\"dept_id\", \"state_id\"]\n",
    "\n",
    "product_sales[\"dept_id\"] = le_dept.fit_transform(product_sales[\"dept_id\"])\n",
    "product_sales[\"state_id\"] = le_state.fit_transform(product_sales[\"state_id\"])\n",
    "\n",
    "pickle.dump(le_dept, open(\"le_dept.pkl\", \"wb\"))\n",
    "pickle.dump(le_state, open(\"le_state.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save train-ready DataFrame, with the best data types.\n",
    "\"\"\"\n",
    "product_sales, _ = reduce_mem_usage(product_sales)\n",
    "pickle.dump(product_sales, open(\"init_train.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>1</td>\n",
       "      <td>001</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1    2   3  4           5                             id  \\\n",
       "0  HOBBIES  1  001  CA  1  validation  HOBBIES_1_001_CA_1_validation   \n",
       "\n",
       "     dept_id state_id store_id        item_id  \n",
       "0  HOBBIES_1       CA     CA_1  HOBBIES_1_001  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For later test building, split the id column to it's components.\n",
    "\"\"\"\n",
    "splitted = sample_submission[\"id\"].str.split(\"_\")\n",
    "splitted = pd.DataFrame.from_dict(dict(zip(splitted.index, splitted.values)), orient=\"index\")\n",
    "splitted[\"id\"] = sample_submission[\"id\"]\n",
    "splitted[\"dept_id\"] = splitted[0].astype(\"str\") + \"_\" + splitted[1].astype(\"str\")\n",
    "splitted[\"state_id\"] = splitted[3]\n",
    "splitted[\"store_id\"] = splitted[3].astype(\"str\") + \"_\" + splitted[4].astype(\"str\")\n",
    "splitted[\"item_id\"] = splitted[\"dept_id\"] + \"_\" + splitted[2]\n",
    "splitted.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simpilfy days with \"events\" into one feature - special_day\n",
    "\"\"\"\n",
    "days_df = calendar.drop([\"date\", \"weekday\"], axis = 1).copy()\n",
    "days_df[\"special_day\"] = np.where((days_df[\"event_name_1\"].astype(\"str\") != \"nan\") |\n",
    "                                (days_df[\"event_name_2\"].astype(\"str\") != \"nan\") , True, False)\n",
    "days_df = days_df.drop([\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\",\n",
    "                       \"month\", \"d\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For test sets, get the last record date.\n",
    "this will allow the notebook to work no matter the dates.\n",
    "\"\"\"\n",
    "last_record =  product_sales.tail(1).copy()\n",
    "cur_wm_yr_wk = last_record[\"wm_yr_wk\"].values[0]\n",
    "cur_wday = product_sales.tail(1)[\"wday\"].values[0]\n",
    "cur_month = product_sales.tail(1)[\"month\"].values[0]\n",
    "cur_mday = product_sales.tail(1)[\"mday\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Building a test set for every day.\n",
    "\"\"\"\n",
    "\n",
    "month_days = {1: 31, 2: 29, 3 :31, 4: 30, 5: 31, 6: 30, 7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12:31}\n",
    "\n",
    "test =splitted[[\"id\", \"dept_id\", \"state_id\", \"item_id\", \"store_id\"]].copy()\n",
    "test_days = []\n",
    "cur_mday = cur_mday + 1\n",
    "cur_wday = (cur_wday + 1) % 8\n",
    "\n",
    "for i in range(1,29):\n",
    "    \n",
    "    test_days.append(test.copy())\n",
    "    if cur_wday == 0: # next week\n",
    "        cur_wday = 1\n",
    "        cur_wm_yr_wk = cur_wm_yr_wk + 1\n",
    "\n",
    "    if cur_mday > month_days[cur_month]: # we are in the next month\n",
    "        cur_month = (cur_month + 1) % 13\n",
    "        if cur_month == 0:\n",
    "            cur_month = 1\n",
    "        \n",
    "        cur_mday = 1 # because the first thing we do in the loop is cur_mday + 1\n",
    "    \n",
    "    test_days[-1][\"mday\"] = cur_mday \n",
    "    test_days[-1][\"wday\"] = cur_wday \n",
    "    test_days[-1][\"month\"] = cur_month \n",
    "    test_days[-1][\"wm_yr_wk\"] = cur_wm_yr_wk \n",
    "    \n",
    "    test_days[-1] = test_days[-1].merge(days_df, on=[\"wm_yr_wk\", \"wday\"], how = \"left\") \n",
    "    test_days[-1] = test_days[-1].merge(sell_prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], how = \"left\")\n",
    "    \n",
    "    cur_mday = cur_mday + 1\n",
    "    cur_wday = (cur_wday + 1) % 8\n",
    "\n",
    "for i, test in enumerate(test_days):\n",
    "    test = test.drop(\"sell_price\", axis = 1)\n",
    "    test.to_csv('tests/test_{}.csv'.format(i), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
