{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_columns\", 50)\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "import pickle\n",
    "from random import sample\n",
    "import random\n",
    "import lightgbm as lgbm\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "random.seed(820)\n",
    "\n",
    "#Evaluator, with it the final models for the ensamble will be picked.\n",
    "# the evaluator takes predictions and scores them for the last month in the train.\n",
    "class WRMSSEEvaluator(object):\n",
    "    \n",
    "    group_ids = ( 'all_id', 'state_id', 'store_id', 'cat_id', 'dept_id', 'item_id',\n",
    "        ['state_id', 'cat_id'],  ['state_id', 'dept_id'], ['store_id', 'cat_id'],\n",
    "        ['store_id', 'dept_id'], ['item_id', 'state_id'], ['item_id', 'store_id'])\n",
    "\n",
    "    def __init__(self, \n",
    "                 train_df: pd.DataFrame, \n",
    "                 valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, \n",
    "                 prices: pd.DataFrame):\n",
    "        '''\n",
    "        intialize and calculate weights\n",
    "        '''\n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.train_target_columns = [i for i in self.train_df.columns if i.startswith('d_')]\n",
    "        self.weight_columns = self.train_df.iloc[:, -28:].columns.tolist()\n",
    "\n",
    "        self.train_df['all_id'] = \"all\"\n",
    "\n",
    "        self.id_columns = [i for i in self.train_df.columns if not i.startswith('d_')]\n",
    "        self.valid_target_columns = [i for i in self.valid_df.columns if i.startswith('d_')]\n",
    "\n",
    "        if not all([c in self.valid_df.columns for c in self.id_columns]):\n",
    "            self.valid_df = pd.concat([self.train_df[self.id_columns], self.valid_df],\n",
    "                                      axis=1, \n",
    "                                      sort=False)\n",
    "        self.train_series = self.trans_30490_to_42840(self.train_df, \n",
    "                                                      self.train_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        self.valid_series = self.trans_30490_to_42840(self.valid_df, \n",
    "                                                      self.valid_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        self.weights = self.get_weight_df()\n",
    "        self.scale = self.get_scale()\n",
    "        self.train_series = None\n",
    "        self.train_df = None\n",
    "        self.prices = None\n",
    "        self.calendar = None\n",
    "\n",
    "    def get_scale(self):\n",
    "        '''\n",
    "        scaling factor for each series ignoring starting zeros\n",
    "        '''\n",
    "        scales = []\n",
    "        for i in tqdm(range(len(self.train_series))):\n",
    "            series = self.train_series.iloc[i].values\n",
    "            series = series[np.argmax(series!=0):]\n",
    "            scale = ((series[1:] - series[:-1]) ** 2).mean()\n",
    "            scales.append(scale)\n",
    "        return np.array(scales)\n",
    "    \n",
    "    def get_name(self, i):\n",
    "        '''\n",
    "        convert a str or list of strings to unique string \n",
    "        used for naming each of 42840 series\n",
    "        '''\n",
    "        if type(i) == str or type(i) == int:\n",
    "            return str(i)\n",
    "        else:\n",
    "            return \"--\".join(i)\n",
    "    \n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        returns weights for each of 42840 series in a dataFrame\n",
    "        \"\"\"\n",
    "        day_to_week = self.calendar.set_index(\"d\")[\"wm_yr_wk\"].to_dict()\n",
    "        weight_df = self.train_df[[\"item_id\", \"store_id\"] + self.weight_columns].set_index(\n",
    "            [\"item_id\", \"store_id\"]\n",
    "        )\n",
    "        weight_df = (\n",
    "            weight_df.stack().reset_index().rename(columns={\"level_2\": \"d\", 0: \"value\"})\n",
    "        )\n",
    "        weight_df[\"wm_yr_wk\"] = weight_df[\"d\"].map(day_to_week)\n",
    "        weight_df = weight_df.merge(\n",
    "            self.prices, how=\"left\", on=[\"item_id\", \"store_id\", \"wm_yr_wk\"]\n",
    "        )\n",
    "        weight_df[\"value\"] = weight_df[\"value\"] * weight_df[\"sell_price\"]\n",
    "        weight_df = weight_df.set_index([\"item_id\", \"store_id\", \"d\"]).unstack(level=2)[\n",
    "            \"value\"\n",
    "        ]\n",
    "        weight_df = weight_df.loc[\n",
    "            zip(self.train_df.item_id, self.train_df.store_id), :\n",
    "        ].reset_index(drop=True)\n",
    "        weight_df = pd.concat(\n",
    "            [self.train_df[self.id_columns], weight_df], axis=1, sort=False\n",
    "        )\n",
    "        weights_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False)):\n",
    "            lv_weight = weight_df.groupby(group_id)[self.weight_columns].sum().sum(axis=1)\n",
    "            lv_weight = lv_weight / lv_weight.sum()\n",
    "            for i in range(len(lv_weight)):\n",
    "                weights_map[self.get_name(lv_weight.index[i])] = np.array(\n",
    "                    [lv_weight.iloc[i]]\n",
    "                )\n",
    "        weights = pd.DataFrame(weights_map).T / len(self.group_ids)\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def trans_30490_to_42840(self, df, cols, group_ids, dis=False):\n",
    "        '''\n",
    "        transform 30490 sries to all 42840 series\n",
    "        '''\n",
    "        series_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False, disable=dis)):\n",
    "            tr = df.groupby(group_id)[cols].sum()\n",
    "            for i in range(len(tr)):\n",
    "                series_map[self.get_name(tr.index[i])] = tr.iloc[i].values\n",
    "        return pd.DataFrame(series_map).T\n",
    "    \n",
    "    def get_rmsse(self, valid_preds) -> pd.Series:\n",
    "        '''\n",
    "        returns rmsse scores for all 42840 series\n",
    "        '''\n",
    "        score = ((self.valid_series - valid_preds) ** 2).mean(axis=1)\n",
    "        rmsse = (score / self.scale).map(np.sqrt)\n",
    "        return rmsse\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "\n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds],\n",
    "                                axis=1, \n",
    "                                sort=False)\n",
    "        valid_preds = self.trans_30490_to_42840(valid_preds, \n",
    "                                                self.valid_target_columns, \n",
    "                                                self.group_ids, \n",
    "                                                True)\n",
    "        self.rmsse = self.get_rmsse(valid_preds)\n",
    "        self.contributors = pd.concat([self.weights, self.rmsse], \n",
    "                                      axis=1, \n",
    "                                      sort=False).prod(axis=1)\n",
    "        return np.sum(self.contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e61ce8eed3445ca92b5a2423020754b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42840.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "train_df = pd.read_csv(\"sales_train_validation.csv\")\n",
    "calendar = pd.read_csv(\"calendar.csv\")\n",
    "prices = pd.read_csv(\"sell_prices.csv\")\n",
    "\n",
    "#Split train-test for evaluator\n",
    "train_fold_df = train_df.iloc[:, :-28]\n",
    "valid_fold_df = train_df.iloc[:, -28:].copy()\n",
    "\n",
    "# Evaluator created\n",
    "e = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "del train_fold_df, train_df, calendar, prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell loads train-reday data sets and pre-trained label encoders.\n",
    "\n",
    "AllTrain = pickle.load(open('train.pkl', \"rb\"))\n",
    "AllTrain[\"d\"] = pickle.load(open(\"init_train_d.pkl\", \"rb\"))\n",
    "\n",
    "AllTrain.dropna(inplace=True) # remove oldest year.\n",
    "\n",
    "le_dept =  pickle.load(open('le_dept.pkl', \"rb\"))\n",
    "le_state = pickle.load(open('le_state.pkl', \"rb\"))\n",
    "\n",
    "le_item =  LabelEncoder()\n",
    "le_store =  LabelEncoder()\n",
    "\n",
    "AllTrain[\"item_id\"] = le_item.fit_transform(AllTrain[\"item_id\"])\n",
    "AllTrain[\"store_id\"] = le_store.fit_transform(AllTrain[\"store_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set validation.\n",
    "Firs27days_mar2016 = ((AllTrain.year == 2016) & (AllTrain.month == 3)& (AllTrain.mday <= 27))\n",
    "FebJan2016 = ((AllTrain.year == 2016) & (AllTrain.month < 3))\n",
    "YearSmallerThan2016 = (AllTrain.year < 2016)\n",
    "\n",
    "MainTrain = AllTrain.loc[Firs27days_mar2016 | FebJan2016 | YearSmallerThan2016].copy()\n",
    "Validation = AllTrain.loc[~AllTrain.index.isin(MainTrain.index)].copy()\n",
    "\n",
    "# Down sample main only.\n",
    "MainTrain_index = list(MainTrain.index)\n",
    "MainTrain_ds_index = sample(MainTrain_index, (len(MainTrain_index)//100) * 32) # 32% of data\n",
    "MainTrain_ds_index = sorted(MainTrain_ds_index)\n",
    "MainTrain = MainTrain.loc[MainTrain_ds_index]\n",
    "MainTrain = MainTrain.reset_index().drop(\"index\", axis = 1)\n",
    "\n",
    "MainTrain = MainTrain.loc[MainTrain.index.isin(MainTrain_ds_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory save\n",
    "del YearSmallerThan2016, FebJan2016, Firs27days_mar2016, AllTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selected\n",
    "MainTrain = MainTrain[[\"sales\", \"id\", \"year\",\"dept_id\",\"wday\", \"item_id\", \"store_id\", \"mean_1_months_ago\",\"mean_2_months_ago\",\"avg_last_year\", \"d\"]]\n",
    "Validation = Validation[[\"sales\", \"id\", \"year\",\"dept_id\",\"wday\", \"item_id\", \"store_id\", \"mean_1_months_ago\",\"mean_2_months_ago\",\"avg_last_year\", \"d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'd' is a feature representing the day sequential number.\n",
    "first_day =  Validation.head(1).d.values[0]\n",
    "Validation['d'] = Validation['d'] - (first_day - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\") # actual file used for submission\n",
    "sample_submission_ = sample_submission.loc[sample_submission[\"id\"].str.contains(\"validation\")].copy() # valudation building\n",
    "sample_submission_copy = sample_submission_.copy() # test building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract product_id\n",
    "def get_product(row):\n",
    "    split_row = row.split(\"_\")\n",
    "    return split_row[0] + \"_\" + split_row[1] + \"_\" + split_row[2] + \"_\" + split_row[3] + \"_\" + split_row[4]\n",
    "\n",
    "sample_submission['product_id'] = sample_submission[\"id\"].apply(get_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ground_truth DataFrames to compare with prediction on the last month in the train set.\n",
    "ground_truth = sample_submission.loc[sample_submission['id'].str.contains(\"validation\")].copy()\n",
    "ground_truth = ground_truth[[\"product_id\"]].copy()\n",
    "\n",
    "for day in range(1,29):\n",
    "    only_day_sales = Validation.loc[Validation[\"d\"].astype(\"int\") == day].copy()\n",
    "    only_day_sales[\"product_id\"] = only_day_sales.id.str[:-len(\"validation\") - 1]\n",
    "    ground_truth[\"F{}\".format(day)] = ground_truth.merge(only_day_sales[[\"product_id\", \"sales\"]], on=\"product_id\")[\"sales\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X - features. y- target (sales)\n",
    "X = MainTrain.drop([\"id\", \"sales\", 'd'], axis =1)\n",
    "X = X.loc[:,~X.columns.duplicated()] # rem dup cols\n",
    "\n",
    "y = MainTrain[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains diefferent models for the ensemble\n",
    "def train_N_models(X,y, help1):\n",
    "    predictors = {}\n",
    "\n",
    "    print(\"trainig\")\n",
    "    if \"rf\" not in help1:\n",
    "        # RF\n",
    "        print(\"rf\")\n",
    "        regr = RandomForestRegressor(max_depth=5, random_state=0,\n",
    "                                  n_estimators=70, n_jobs = -1)\n",
    "        regr.fit(X, y) \n",
    "        predictors[\"rf\"] = regr\n",
    "        help1[\"rf\"] = regr\n",
    "\n",
    "\n",
    "    if \"catboost\" not in help1:\n",
    "        #     catboost\n",
    "        print(\"catboost\")\n",
    "        catb = CatBoostRegressor(iterations=100,\n",
    "                                  learning_rate=0.078,\n",
    "                                  depth=10,\n",
    "                                random_seed = 32,\n",
    "                                logging_level = \"Silent\",\n",
    "                                thread_count = -1)\n",
    "        catb.fit(X, y)\n",
    "        predictors[\"catboost\"] = catb\n",
    "        help1[\"catboost\"] = catb\n",
    "\n",
    "\n",
    "    if \"XGBoost\" not in help1:\n",
    "        # XGBoost\n",
    "        print(\"XGBoost\")\n",
    "        model = xgb.XGBRegressor(colsample_bytree=0.4,\n",
    "                         gamma=0,                 \n",
    "                         learning_rate=0.17,\n",
    "                         max_depth=3,\n",
    "                         min_child_weight=1.5,\n",
    "                         n_estimators=70,                                                                    \n",
    "                         reg_alpha=0.75,\n",
    "                         reg_lambda=0.45,\n",
    "                         subsample=0.6,\n",
    "                         seed=42) \n",
    "\n",
    "        model.fit(X,y)\n",
    "        predictors[\"xgboost\"] = model\n",
    "        help1[\"XGBoost\"] = model\n",
    "\n",
    "    if \"lightgbm\" not in help1:\n",
    "        # lightgbm\n",
    "        print(\"lightgbm\")\n",
    "        parms = {\"boosting_type\" : 'dart',\n",
    "                 \"num_leaves\" : 3,\n",
    "                 \"max_depth\" :2, \n",
    "                 'learning_rate':0.25,\n",
    "                 \"n_estimators\" : 80,\n",
    "                 \"objective\" : \"regression\", \n",
    "                 \"min_split_gain\" : 0,\n",
    "                 \"min_child_weight\" : 0.001,\n",
    "                 \"min_child_samples\" : 20,\n",
    "                 \"reg_alpha\" : 0,\n",
    "                 \"reg_lambda\" : 0, \n",
    "                 \"random_state\" : 1406,\n",
    "                 \"n_jobs\" : -1,\n",
    "                 \"silent\" : False}\n",
    "\n",
    "        model = lgbm.LGBMRegressor(boosting_type = parms[\"boosting_type\"],\n",
    "                                  num_leaves = parms[\"num_leaves\"],max_depth = parms[\"max_depth\"],\n",
    "                                  learning_rate = parms[\"learning_rate\"],n_estimators = parms[\"n_estimators\"],\n",
    "                                  objective = parms[\"objective\"],min_split_gain = parms[\"min_split_gain\"],\n",
    "                                  min_child_weight = parms[\"min_child_weight\"],\n",
    "                                  min_child_samples = parms[\"min_child_samples\"],reg_alpha = parms[\"reg_alpha\"],\n",
    "                                  reg_lambda = parms[\"reg_lambda\"],random_state = parms[\"random_state\"],\n",
    "                                  n_jobs = parms[\"n_jobs\"],silent = parms[\"silent\"])\n",
    "\n",
    "        model.fit(X, y)\n",
    "        predictors[\"lightgbm\"] = model\n",
    "        help1[\"lightgbm\"] = model\n",
    "\n",
    "\n",
    "    if \"lr\" not in help1:\n",
    "        print(\"lr\")\n",
    "        # liniar regression \n",
    "        lm = linear_model.LinearRegression(n_jobs = -1)\n",
    "        model = lm.fit(X,y)\n",
    "        predictors[\"lr\"] = model\n",
    "        help1[\"lr\"] = model\n",
    "\n",
    "\n",
    "    if \"NN\" not in help1:\n",
    "        print(\"NN\")\n",
    "        # NN\n",
    "        NN_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        NN_model.add(Dense(30, kernel_initializer=\"glorot_normal\",input_dim =X.shape[1], activation=\"selu\"))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        NN_model.add(Dense(15, kernel_initializer=\"glorot_normal\",activation=\"elu\"))\n",
    "        NN_model.add(Dense(15, kernel_initializer=\"glorot_normal\",activation=\"elu\"))\n",
    "\n",
    "        # The Output Layer :\n",
    "        NN_model.add(Dense(1, kernel_initializer='glorot_normal',activation=\"elu\"))\n",
    "\n",
    "        # Compile the network :\n",
    "        NN_model.compile(loss=\"mean_squared_error\", optimizer=\"Adadelta\", metrics=[\"acc\"])\n",
    "\n",
    "        NN_model.fit(X, y, epochs=1, batch_size=400, validation_split = 0.2, verbose = True) \n",
    "        predictors[\"NN\"] = NN_model\n",
    "        help1[\"NN\"] = NN_model\n",
    "\n",
    "\n",
    "    return predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "help1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig\n",
      "rf\n",
      "catboost\n",
      "XGBoost\n",
      "lightgbm\n",
      "lr\n",
      "NN\n",
      "7231/7231 [==============================] - 70s 10ms/step - loss: 20.7785 - acc: 0.6535 - val_loss: 22.1148 - val_acc: 0.6792\n"
     ]
    }
   ],
   "source": [
    "# Train without the last month, for validation\n",
    "if \"d\" in X:\n",
    "    predictors_valid = train_N_models(X.drop(\"d\", axis = 1) ,y, help1)\n",
    "else:\n",
    "    predictors_valid = train_N_models(X ,y, help1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every day there is a test DataFrame containing the features of that day.\n",
    "# In this case we only use the validation rows\n",
    "test_days = []\n",
    "test_columns = list(MainTrain.columns)\n",
    "test_columns.remove(\"sales\")\n",
    "test_columns.remove(\"d\")\n",
    "\n",
    "for day in range(0, 28):\n",
    "    test_days.append(pickle.load(open(\"tests/test_{}.pkl\".format(day), \"rb\")))\n",
    "    test_days[day] = test_days[day].loc[test_days[day][\"id\"].str.contains(\"validation\")].copy()\n",
    "\n",
    "    test_days[-1][\"dept_id\"] = le_dept.transform(test_days[-1][\"dept_id\"])\n",
    "    test_days[-1][\"state_id\"] = le_state.transform(test_days[-1][\"state_id\"])\n",
    "    test_days[-1][\"item_id\"] = le_item.transform(test_days[-1][\"item_id\"])\n",
    "    test_days[-1][\"store_id\"] = le_store.transform(test_days[-1][\"store_id\"])\n",
    "    test_days[-1] = test_days[-1][test_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make validation days - DataFrame for every day in the validation set.\n",
    "validation_days = []\n",
    "test_days_cols = test_days[0].columns\n",
    "for day in range(1,29):\n",
    "    valid_day = Validation.loc[Validation.d == day][test_days_cols]\n",
    "    valid_day = valid_day.loc[:,~valid_day.columns.duplicated()] # rem dup cols\n",
    "\n",
    "    valid_day = valid_day.set_index('item_id')\n",
    "    valid_day = valid_day.reindex(index=test_days[0]['item_id'])\n",
    "    validation_days.append(valid_day.reset_index())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes prediction given a validation day DataFrame\n",
    "def predict_28_days_validation(model, X):\n",
    "    temp = pd.DataFrame()\n",
    "    for day, validation in enumerate(validation_days):\n",
    "        print(day, end = \"  \")\n",
    "        col = \"F{}\".format(day + 1)\n",
    "        sample_submission_copy[col] = model.predict(validation_days[day].drop([\"id\"], axis = 1)[X.columns])\n",
    "        sample_submission_copy[col] =  sample_submission_copy[col].round(1)\n",
    "        temp[col] = sample_submission_copy[col].to_numpy().flatten()    \n",
    "    print()\n",
    "    return temp.to_numpy()\n",
    "# column is every product * 28 days all the way down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "catboost\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "xgboost\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "lightgbm\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "lr\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "NN\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n"
     ]
    }
   ],
   "source": [
    "# Predictions for ensemble\n",
    "preds_validation = pd.DataFrame()\n",
    "for predictor_name, predictor in predictors_valid.items():\n",
    "    print(predictor_name)\n",
    "    preds_validation[predictor_name] = predict_28_days_validation(predictor, X).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_validation[\"ground_truth\"] = ground_truth.drop(\"product_id\", axis =1).to_numpy().flatten()\n",
    "preds_validation = preds_validation.clip(0, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial ensemble \n",
    "X_ens = preds_validation.drop(\"ground_truth\", axis = 1)\n",
    "y_ens = preds_validation[\"ground_truth\"]\n",
    "\n",
    "\n",
    "regr = xgb.XGBRegressor (eta =0.1,  \n",
    "                        nthread = -1, \n",
    "                        n_estimators= 30, \n",
    "                        max_depth= 2, \n",
    "                        max_delta_step= 16,\n",
    "                         colsample_bytree= 0.4,\n",
    "                         scale_pos_weight= 0.9,\n",
    "                         base_score= 0.9,\n",
    "                         eval_metric= 'rmse')\n",
    "regr.fit(X_ens, y_ens) \n",
    "pickle.dump(regr, open(\"regr_ens.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation = Validation.drop(\"d\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5108"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainig\n",
      "rf\n",
      "catboost\n",
      "XGBoost\n",
      "[08:07:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\gbm\\gbtree.cc:138: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "lightgbm\n",
      "lr\n",
      "NN\n",
      "8938/8938 [==============================] - 86s 10ms/step - loss: 20.6021 - acc: 0.6596 - val_loss: 20.4906 - val_acc: 0.5633\n"
     ]
    }
   ],
   "source": [
    "# Train on all the months in the data\n",
    "help1 = {}\n",
    "\n",
    "MainTrain = MainTrain.loc[:,~MainTrain.columns.duplicated()] # rem dup cols\n",
    "Validation = Validation.loc[:,~Validation.columns.duplicated()] # rem dup cols\n",
    "\n",
    "''\n",
    "X = MainTrain.append(Validation)\n",
    "y = X[\"sales\"]\n",
    "\n",
    "X = X.drop([\"item_id\", \"id\", \"sales\", \"d\"], axis =1)\n",
    "X = X.loc[:,~X.columns.duplicated()] # rem dup cols\n",
    "\n",
    "predictors_test = train_N_models(X, y, help1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "catboost\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "xgboost\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "lightgbm\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "lr\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "NN\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n"
     ]
    }
   ],
   "source": [
    "# Predict for every day in the test set\n",
    "preds_test = pd.DataFrame()\n",
    "for predictor_name, predictor in predictors_test.items():\n",
    "    print(predictor_name)\n",
    "    preds_test[predictor_name] = predict_28_days_validation(predictor, X).flatten()       \n",
    "preds_test = preds_test.clip(0,99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "0.9044483070942493\n",
      "adding rf helped! grade now: 0.9044483070942493 prev grade: 999\n",
      "Index(['rf'], dtype='object')\n",
      "catboost\n",
      "0.7366866798221225\n",
      "adding catboost helped! grade now: 0.7366866798221225 prev grade: 0.9044483070942493\n",
      "Index(['rf', 'catboost'], dtype='object')\n",
      "xgboost\n",
      "0.7047581040672235\n",
      "adding xgboost helped! grade now: 0.7047581040672235 prev grade: 0.7366866798221225\n",
      "Index(['rf', 'catboost', 'xgboost'], dtype='object')\n",
      "lightgbm\n",
      "0.7752641444848231\n",
      "adding lightgbm did not help. get out.\n",
      "lr\n",
      "0.7717258052469753\n",
      "adding lr did not help. get out.\n",
      "NN\n",
      "0.7291783631081239\n",
      "adding NN did not help. get out.\n"
     ]
    }
   ],
   "source": [
    "# Final models selection.\n",
    "X_ens = preds_validation.drop(\"ground_truth\", axis = 1)\n",
    "y_ens = preds_validation[\"ground_truth\"]\n",
    "\n",
    "regr = xgb.XGBRegressor (eta =0.3,  \n",
    "                        nthread = -1, \n",
    "                        n_estimators= 50, \n",
    "                        max_depth= 4, \n",
    "                        max_delta_step= 6,\n",
    "                         colsample_bytree= 0.4,\n",
    "#                          scale_pos_weight= 0.9,\n",
    "                         base_score= 0.9,\n",
    "                         eval_metric= 'rmse')\n",
    "\n",
    "best_grade = 999\n",
    "save_x_ens = X_ens.copy()\n",
    "df = pd.DataFrame()\n",
    "for i, model in enumerate(X_ens):\n",
    "    model_name = list(save_x_ens.columns)[i]\n",
    "    print(model_name)\n",
    "    df[model_name] = X_ens[model_name]\n",
    "    \n",
    "    regr.fit(df, y_ens)\n",
    "    \n",
    "    Ens_preds = regr.predict(preds_test[df.columns])\n",
    "    Ens_preds = Ens_preds.reshape(sample_submission_.shape[0], 28)\n",
    "    Ens_preds_c = Ens_preds\n",
    "    grade = e.score(Ens_preds_c)\n",
    "    print(grade)\n",
    "    \n",
    "    if grade < best_grade:  # improve\n",
    "        print(\"adding {} helped! grade now: {} prev grade: {}\".format(model_name, grade, best_grade))\n",
    "        best_grade = grade\n",
    "        print(df.columns)\n",
    "        columns_best_regr = df.columns\n",
    "    else:\n",
    "        print(\"adding {} did not help. get out.\".format(model_name))\n",
    "        df = df.drop(model_name, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in preds_test.columns:\n",
    "    if col not in columns_best_regr:\n",
    "        preds_test = preds_test.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7047581040672235"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final ensemble.\n",
    "regr.fit(df[columns_best_regr], y_ens)\n",
    "\n",
    "Ens_preds = regr.predict(preds_test[columns_best_regr])\n",
    "Ens_preds = Ens_preds.reshape(sample_submission_.shape[0], 28)\n",
    "e.score(Ens_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every day there is a test DataFrame containing the features of that day.\n",
    "# In this case we only use all the rows - validation and test\n",
    "test_days = []\n",
    "for day in range(0, 28):\n",
    "    test_days.append(pickle.load(open(\"tests/test_{}.pkl\".format(day), \"rb\")))\n",
    "    test_days[-1][\"dept_id\"] = le_dept.transform(test_days[-1][\"dept_id\"])\n",
    "    test_days[-1][\"state_id\"] = le_state.transform(test_days[-1][\"state_id\"])\n",
    "    test_days[-1][\"item_id\"] = le_item.transform(test_days[-1][\"item_id\"])\n",
    "    test_days[-1][\"store_id\"] = le_store.transform(test_days[-1][\"store_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_28_days_test(model, X):\n",
    "    temp = pd.DataFrame()\n",
    "    for day, test in enumerate(test_days):\n",
    "        print(day, end = \"  \")\n",
    "        col = \"F{}\".format(day + 1)\n",
    "        sample_submission[col] = model.predict(test.drop([\"id\"], axis = 1)[X.columns])\n",
    "        sample_submission[col] =  sample_submission[col].round(1)\n",
    "        temp[col] = sample_submission[col].to_numpy().flatten()    \n",
    "    print()\n",
    "    return temp.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memory cleanup\n",
    "whos = %who_ls\n",
    "if \"Ens_preds\" in whos:\n",
    "    del Ens_preds\n",
    "    \n",
    "if \"X_ens\" in whos:\n",
    "    del X_ens\n",
    "\n",
    "if \"Validation\" in whos:\n",
    "    del Validation\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "catboost\n",
      "xgboost\n"
     ]
    }
   ],
   "source": [
    "for predictor_name in columns_best_regr:\n",
    "    print(predictor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting!\n",
      "rf\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "catboost\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n",
      "xgboost\n",
      "0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  \n"
     ]
    }
   ],
   "source": [
    "# Final predictions.\n",
    "print(\"predicting!\")\n",
    "\n",
    "preds = pd.DataFrame()   \n",
    "    \n",
    "\n",
    "for predictor_name in columns_best_regr:\n",
    "    print(predictor_name)\n",
    "    preds[predictor_name] = predict_28_days_test(predictors_test[predictor_name], X).flatten()\n",
    "\n",
    "if \"lr\" in preds:\n",
    "    preds[\"lr\"] = preds[\"lr\"].clip(lower = 0.1)\n",
    "    \n",
    "Ens_preds_test = regr.predict(preds)\n",
    "Ens_preds_test = Ens_preds_test.reshape(sample_submission.shape[0], 28)\n",
    "    \n",
    "F_cols = [\"F{}\".format(i) for i in range(1,29)]\n",
    "sample_submission[F_cols] = Ens_preds_test\n",
    "sample_submission = sample_submission.round(1)\n",
    "sample_submission[F_cols] = sample_submission[F_cols].clip(lower = 0.01, axis=0) # drop negatives\n",
    "\n",
    "if \"product_id\"  in sample_submission:\n",
    "    sample_submission =  sample_submission.drop(\"product_id\", axis = 1)\n",
    "sample_submission.to_csv(\"submission.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
